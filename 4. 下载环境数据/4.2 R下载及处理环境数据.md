## 4.下载环境数据

### 说 明：

```
环境变量在使用时因为可能会有na值，这部分无法在plot()或者其他绘图方式中绘制出。因此需要在绘制时，将!is.na()纳入其中：
plot(!is.na(mask), legend=FALSE)
plot(!is.na(dem))
```

### 4.1 下载数据

#### 4.1.1 getData():: 国家shp

```{r eval=FALSE} 
## 下载国家信息：##注意这个下载中国的数不能使用，因为中国的范围不全；
library(raster)
#Get Data
austria0 <- getData('GADM' , country="AUT", level=0)
austria1 <- getData('GADM' , country="AUT", level=1)
#Plot  ##其中level表示不同国家下属层级的展示：
par(mfrow(2,1))
plot(austria0, main="Adm. Boundaries Austria Level 0")
plot(austria1, main="Adm. Boundaries Austria Level 1")
```

#### 4.1.2 getData::环境信息

```{r eval=FALSE} 
##raster getData
currentEnv <- getData("worldclim", var="bio", res=10)

##getdataworldclim2070
futureEnv=getData('CMIP5', var='bio', res=2.5, rcp=85, model='HE', year=70)
## 修改未来文件的文件名与现代一致！！
names(futureEnv)=names(currentEnv)
```

#### 4.1.3 getData::90m高程信息

```{r eval=FALSE} 
## 下载90m高程信息：
## getData()下载的的高程数据为数据块，需要镶嵌才可以使用：
## 其中lon和lat表示对应的全球90m高程数据块；
srtm <- getData('SRTM', lon=16, lat=48)
## 栅格块 镶嵌，使用raster::mosaic():
srtm2 <- getData('SRTM', lon=13, lat=48)
srtm3 <- getData('SRTM', lon=9, lat=48)
srtmmosaic <- mosaic(srtm, srtm2, srtm3, fun=mean)

## 按照指定国家下载高程信息，并自动拼接：
library(raster)
library(rgeos)
library(rasterVis)
## 构建范围：
country_name <- "AUT"   #Austria
shp <- shapefile("srtm/tiles.shp")  #Path to downloaded SRTM Tiles

#Get country geometry first
country <- getData("GADM", 
                   country = country_name, 
                   level=0)

#Intersect country geometry and tile grid
intersects <- gIntersects(country, shp, byid=T)
tiles      <- shp[intersects[,1],]

#Download tiles
srtm_list  <- list()
for(i in 1:length(tiles)) {
  lon <- extent(tiles[i,])[1]  + (extent(tiles[i,])[2] - extent(tiles[i,])[1]) / 2
  lat <- extent(tiles[i,])[3]  + (extent(tiles[i,])[4] - extent(tiles[i,])[3]) / 2
  
  tile <- getData('SRTM', 
                  lon=lon, 
                  lat=lat)
  
  srtm_list[[i]] <- tile
}

#Mosaic tiles
srtm_list$fun <- mean 
srtm_mosaic   <- do.call(mosaic, srtm_list)

#Crop tiles to country borders
srtm_crop     <- mask(srtm_mosaic, country)

#Plot  ##　 plotted with {rasterVis}:
p <- levelplot(srtm_mosaic)
p + layer(sp.lines(country, 
                   lwd=0.8, 
                   col='darkgray'))
```



#### 4.1.4 下载网页链接文件

```{r eval=FALSE} 
## download.file(url,destfile="")
##使用下面类似代码或许可以以后直接从Ｒ下载文件到指定安装包；
url <- "http://datadrivensecurity.info/book/ch03/data/reputation.data"
req <- "reputation.data"
if(file.access(req)){　　
##很多网络文件是不提供r下载权限的，可能需要探索Rcurl包的使用；
  download.file(url,req)
}
```



### 4.2数据目录及简要说明

```
## 关于大气环流模型的解读：
主要包含两种方法：一种是静态统计学方法，另外一种是动态建模；
## 静态统计学方法：
	主要通过对原始气候站点，进行薄板样条空间插值，将更高空间精度的数据转为降尺度的序列空间尺度；
## 静态统计学方法的演技假设：
气候变化仅在很长的距离内变化（即与GCM边区尺寸一样大）。
基线中的变量（“当前气候”）之间的关系很可能在未来保持不变。
静态建模的研究方法可能在高度异质性景观中并不成立，因为再这些景观中地形会引起异常的环境变化。但对于环境较为均质(## 如沙漠和其他均质性区域)
## 动态统计学方法：
	主要源-流模型和空间势能转换等原理，采用动态建模的方式考虑到地形变化和局域异质性差异，并对某些空间异质性区域实施强烈的约束；
```

```
##目前关于数据库，多采用来自于worldclim的环境数据，上述环境数据分为两个独立的版本；

##其中V1.4版本目前仍提供古气候建模，包括末次冰期、末次间冰期和中新世的古气候建模结果；

##其中V2.0版本，目前更新了关于当代气候建模的结果，以及更新了未来气候建模的结果；并且未来气候建模全部采用图层叠合的方式构建中同一张图层中。需要采用raster包分解循环导出；另外需要注意是在bioclimvaribles主要包含温度变量和降水变量，而且温度和降水变量也同样经过矫正；
```

### 4.3构筑本地环境变量集合

#### 4.3.1 构建集合环境图层

```{r eval =FALSE}
## 注意raster::stack()构建时需要tif文件的全路径(full.name= TRUE)
cuurentenvs <- list.files(path=paste0("E:/globaltest2/"),pattern='tif', full.names=TRUE )
##stack：将环境图层打包组合
envs <- stack(currentEnv)  ## 或者 clim <- raster::stack(clim_list) 
##brick：将环境图层叠加组合，大部分情况下brick容易报错；
envs <- brick(currentEnv)

## 另外一种构建栅格数据集的方法是对原有数据集进行处理，去除冗余变量；
## 参见下面链接：
https://adnguyen.github.io/demos/RasterPCA_demo.html#using-rasterpca-function
```

#### 4.3.2  删除和筛选图层

```{r eval =FALSE}
## 这一步对于大规模建模数据是相对重要的，可以避免了反复的获取数据，直接利用代码提出即可；
## 但是需要和栅格批量重命名相关连使用；
currentEnv=dropLayer(currentEnv, c("bio2", "bio3", "bio4", "bio10", "bio11", "bio13", "bio14", "bio15"))
futureEnv=dropLayer(futureEnv, c("bio2", "bio3", "bio4", "bio10", "bio11", "bio13", "bio14", "bio15"))

## 选择指定变量(筛选)：
## var()可以使用list.files()查询后指定：
var<-c("bio1","bio5","bio7","bio12","bio16","bio18")
clim<-clim[[which(names(clim)%in%var)]]
```

#### 4.3.3 解开多波段数据

```{r eval =FALSE}
#TIF单波段分解多波段；
## 目前worldclim提供的未来数据为多波段类型：
rm(list=ls())
library(reshape2);library(viridis);library(ggplot2);library(gridExtra)
setwd("C:/admin/desktop/future/CNRM-CM6-1")
input = list.files(pattern = '.tif$')
d = stack(input) ##这里应该是brick转stack；
d_list = as.list(d)  ##解开栅格组，构成列表的形式；
dir.create('output')  ##创建文件夹；
export_band<-function(x){
  names = names(x)
  output = paste0('C:/admin/desktop/future/CNRM-CM6-1/output/',names,'.tif')
  writeRaster(x,output,format ='GTiff' ,
              overwrite = T)}
lapply(d_list,export_band)
```

```{r eval =FALSE}
### 多核并行计算：
setwd("C:/Users/admin/Desktop/wc2.1_2.5m_bioc_BCC-CSM2-MR_ssp585_2021-2040")
input = list.files(pattern = '.tif$')
d = stack(input) ##这里应该是brick转stack；
d_list = as.list(d)
library(parallel) #用于并行计算
library(snowfall)  # 载入snowfall包
sfInit(parallel = TRUE, cpus = detectCores() - 1)
sfLibrary(raster) 
sfLibrary(base)
sfExport("d_list")


export_band<-function(x){
  names = names(x)
  output = paste0('H:/中国地区环境数据/中国现代及未来气候掩膜worldclim_V2/ssp585/ssp585-202040/',names,'.tif')
  writeRaster(x,output,format ='GTiff' ,
              overwrite = T)}
sfLapply(d_list,export_band)
sfStop()
```

```{r eval =FALSE}
##NC数据单波段分解：##且仅支持nc格式，不支持nc4格式；
## 见：4.6世界土壤数据HSWD批处理
```

### 4.4   worldclim未来环境数据批处理

#### 4.4.1 设置工作环境

```{r eval =F}
## 养成习惯：
rm(list = ls())
## 设置工作路径:
## C:/Users/chengshanmei/Desktop
## 以该文件名为例：./ssp126-202040
setwd("C:/Users/chengshanmei/Desktop")
## 加载工具包：
library(raster)
```

#### 4.4.2 构建栅格掩膜

构架栅格掩膜中涉及到将tif文件作为栅格；一般如果建模范围是正方形或者长方形可以直接使用对应的横纵坐标的范围；如果不规则，则需要使用raster包下的rasterToPolygons用于帮助处理；

##因为时间限制，此处是采用批量替代的依次将ssp126、245、370和585以及对应的时期进行交叉替换。但笔者后来查资料想到可以使用列表交叉的方法将所有的文件路径构建成列表的形式；然后将下面构建的代码打包，构建循环体，一步导出即可；关于如何构建列表交叉：https://blog.csdn.net/Cocaine_bai/article/details/80506037

```{r eval =F}
##导入掩膜；shp或者tif格式----
## 利用栅格文件获取掩膜范围；----
##以下获得栅格文件的方法是基于栅格转面或者转线；
##如果加载的栅格文件是一个标准的正方形或长方形可以使用以下代码获得范围；
## 这里的bio2为掩膜文件,后同:
extenta <- extent(raster("./bio2.tif")) 
##如果加载的栅格文件是不规则的，可以使用raster::rasterToPolygons()
##使用asterToPolygons()获得是栅格面的shp文件；
## 栅格转shp面文件：加载较慢；有时可利用【,dissolve = TRUE】获得融合shp面文件；
extentb <- raster::rasterToPolygons(raster("./bio2.tif"))
## 栅格转shp边界线文件；加载较快； 
##在实验中，extentb掩膜不成功；extentb所获取的线文件可用于掩膜
extentc <- raster::rasterToContour(raster("./bio2.tif"))
```

```{r eval =F}
##以下代码经试验后不可行，但获取栅格边界的功能可以通过arcgis的3D分析功能-栅格处理中找到栅格范围工具来获取；
## 但为了加速掩膜，需要获得栅格的外边界，也就是栅格范围，这在arcgis中可以实现；
## R实现获取栅格边界，可能需要
## boundaries(x, type='inner', classes=FALSE, directions=8, asNA=FALSE, filename="", ...)
bio22 <- raster("./bio2.tif")
##基于boundaries仍然是一个栅格边界文件；此边界文件可以直接用于掩膜；
extentd <- boundaries(bio22,type="outer")
```

#### 4.4.3  单因子及多因子掩膜

```{r eval =F}
## 使用stack构建全部环境因子集合，用于批量掩膜；
bios <- stack(list.files(path="./ssp126-202040",pattern="tif",full.name =TRUE))

##单个环境因子掩膜后
##定义单个环境变量；
## 从stack()中读取单个栅格的方法；
##如下两种方法均可以；
bio2 <- bios[[1]]
bio3 <- bios$wc2.1_2.5m_bioc_BCC.CSM2.MR_ssp126_2021.2040.2
## 定义掩膜；
##使用raster::rasterToContour()
biocrop <- crop(bio3,extent(extentc))
##使用raster::boundaries()
biocrop1 <- crop(bio2,extent(extentd))
## plot(bio2)

## 多个环境因子掩膜；其中biocrops为一个stack()
biocrops <- crop(bios,extent(extentc))
```

#### 4.4.4  批量掩膜及asc导出

```{r eval =F}
##单变量因子导出：
writeRaster(biocrop,"./ssp126-202040/bio2.asc",format="ascii")

##多变量因子导出：
##注意这里不需要该tif的后缀，这里只是作为路径名，后面输出的结果应该也是asc作为结尾；
## 列出文件完整路径
namesx <- list.files(path="./ssp126-202040",pattern = "tif",full.names = TRUE)
## 列出文件名；
namesy <- list.files(path="./ssp126-202040",pattern = "tif")
namesy[1]
##多个环境因子转为asc后导出；
export_band<-function(x){
  names = namesy[x]
  output = paste0('C:/Users/chengshanmei/Desktop/ssp126-202040/',names)
  writeRaster(biocrops[[x]],output,format="ascii" ,
              overwrite = T)}
lapply(1:length(namesy),export_band)
```

#### 4.4.5 掩膜后文件批量重命名

##此处重命名的目的是因子maxent在投影过程中需要保持现代气候和未来气候的环境因子名称相同才可以进行；

```{r eval =F}
##关于file.rename()函数的作用是将采用from和to的形式，需要保证两者均对应完整路径下的向量列表，命名才可以进行；
##注意此处重命名出错；
##需要保证导出的环境变量能和对应的现代的环境变量的值对应；此处加载的bio系列值和实际转为asc值之间不匹配；经检验，所有环境数据栅格转为asc之后均具有相同的排序，因此可以指定对应的迭代顺序来实现名称替换。
newname<-list("bio2","bio6","bio10","bio12","bio14","bio15","bio19")
news <- as.vector(paste0("C:/Users/chengshanmei/Desktop/ssp126-202040/",newname,".tif"))
file.rename(from = list.files(path="C:/Users/chengshanmei/Desktop/ssp126-202040/",pattern = "tif",full.names = TRUE),
            to = news)
```

```{r eval =F}
## 批量重命名的另外一种方式：
## 根据之前查到的代码，只需要保证，数据之间是相对应的；
## 但很容易出现不匹配，然后数据间乱组的现象；需要重命名后复核~！
## names("现代气候文件夹") = names("未来气候文件夹")
```

#### 4.4.6 实际项目代码(并行)

```{r eval =F}
##项目：保存worldclim环境数据：
## 中国范围：
rm(list = ls())
setwd("F:\\未来气候")
library(maptools)
library(raster)
# 获取中国shp文件；
CHN<- getData('GADM' , country="CHN", level=0)
dir.create("./CHINA_SHP_WGS84")
writeSpatialShape(CHN,"./CHINA_SHP_WGS84/chinashp.shp")
##读取中国范围shp用于掩膜
chinashp <- readShapeSpatial("./CHINA_SHP_WGS84/chinashp.shp")

## 批量掩膜：
## 批量构筑文件夹路径：
setwdd <- "F:/未来气候/"
times <- c("202040","204060","206080","2080100")
ssps <- c("ssp126","ssp245","ssp370","ssp585")
routes=c()
for(i in 1:4){
  for(x in 1:4){
    route <- paste0(setwdd,ssps[i],"/",ssps[i],"-",times[x],"/")
    routes <- cbind(routes,route)
  }
}
routes[2]

##构建函数，迭代输出：
## 构建掩膜文件：使用mask()掩膜效率极低：
## 构建并行环境运行：
## install.packages(c("foreach","doParalle"))
library(parallel) #用于并行计算
library(snowfall)  # 载入snowfall包
# 并行初始化
extents <- chinashp
sfInit(parallel = TRUE, cpus = detectCores() - 1)
sfLibrary(raster) 
sfLibrary(base)
sfExport("routes")
sfExport("extents")
## 运行批量掩膜

out <- function(x){	
  bios <- stack(list.files(path=x,pattern="tif",full.name =TRUE))
  ## 注意这里先裁剪再掩膜是效果最高的批处理方法：
  biocrops <- mask(crop(bios,extents),extents)
  namesy <- list.files(path=x,pattern = "tif")
  export_band<-function(y){
    names = namesy[y]
    output = paste0(x,names)
    writeRaster(biocrops[[y]],output,format="ascii" ,
                overwrite = T)}
  sfLapply(1:length(namesy),export_band)
}
sfLapply(routes,out)
## sfStop()

## 经过如上操作，发生范围选择错误；原因是使用crop裁剪；
## 经过getdata下载的数据为中国范围，而不是中国的边缘shp文件；
## 批量删除，所有已经处理好的asc文件：
outdel <- function(x){
  namesy <- list.files(path=x,pattern = "asc",full.names = T)
  export_band_del<-function(y){
    names = namesy[y]
    file.remove(names)}
  lapply(1:length(namesy),export_band_del)
}
lapply(routes,outdel)
## 批量重命名：需要注意命名时所有list文件有一定的排序规则，并且所有文件夹的排序规则是一致的；需要导出排名重新命名：
rename <- function(x){
    ##注意夏敏的 list中必须是字符串形式的数据；“x”
  newname<-list("bio10","bio12","bio14","bio15","bio19","bio2","bio6")
  news <- as.vector(paste0(x,newname,".asc"))
  file.rename(from = list.files(path=x ,pattern = "asc",full.names = TRUE),to = news)
}
lapply(routes,rename)

### 补充：关键字符的提取，用于文件重命名：

## 提取中国bio命名：
## 分别以bio_ 和"\\."
rm(list = ls())
nnn <- list.files(path="F:\\未来气候\\CHN_WC2.5_BIO",pattern="asc",full.name =TRUE)

out3 <- list()
for(i in 1:length(nnn)){
  out4 <- strsplit((as.character(nnn[i])),split = "bio_")
  out4 <- strsplit(out4[[1]][2],split= "\\.")
  out4 <-   unlist(out4)
  out3 <- cbind(out3,out4)
}
out3 <- t(data.frame(out3))
out5 <- as.character(out3[,1])
out_end_name <- paste0("bio",out5)
```

#### 4.4.7 实际项目代码2(并行)

```R
## 构建批循环的方式来解压缩未来气候数据：
## 该代码并行解压并求不同年份的均值；
# 数据路径：E:\临时\FUT

dir("E:/临时/FUT")
setwd("E:/临时/FUT")
dir("./MIROC6/")
# MIROC6 <- list.files("./MIROC6/",pattern = "zip",full.names = T)
## 设计输出路径文件夹：####
dir.create("./FUTM")
setwddd <- "E:/临时/FUT/FUTM"
times <- c("202040","204060","206080","2080100")
ssps <- c("ssp126","ssp245","ssp370","ssp585")
routey=c()
### 构建文件路径：routey ####
for(i in 1:4){
  for(x in 1:4){
    route <- paste0(setwddd,"/",ssps[i],"-",times[x],"/")
    routey <- cbind(routey,route)
  }
}

routey <- as.vector(routey)
for(i in 1:16){
  dir.create(routey[i])
}
routey[1]

library(raster)
library(tidyverse)
t1 <- list.files("./M2",pattern = "tif",full.names = T)
## 并行脚本：####
library(parallel) #用于并行计算
library(snowfall)  # 载入snowfall包
sfInit(parallel = TRUE, cpus = detectCores() - 4)
sfLibrary(raster) 
sfLibrary(base)
sfLibrary(tidyverse)
sfExport("routey")
sfExport("t1")
export_band <- function(x){
  t1 <- stack(t1[x]) %>% as.list(.)
  export <- function(y){
    output <- paste0(routey[x],names(t1[[y]]),".tif")
    writeRaster(t1[[y]],output,format ='GTiff',overwrite=TRUE )
  }
  sfLapply(1:19,export)
}
lapply(1:16,export_band)



rm(routey)
rm(t1)
## 设计输出路径文件夹2：####
dir.create("./FUTMC")
setwddd <- "E:/临时/FUT/FUTMC"
times <- c("202040","204060","206080","2080100")
ssps <- c("ssp126","ssp245","ssp370","ssp585")
routey=c()
### 构建文件路径：routey 


## 设计输出路径文件夹3：####

setwddd <- "E:/临时/FUT/BBCMR"
times <- c("202040","204060","206080","2080100")
ssps <- c("ssp126","ssp245","ssp370","ssp585")
routey=c()
### 构建文件路径：routey ####
for(i in 1:4){
  for(x in 1:4){
    route <- paste0(setwddd,"/",ssps[i],"-",times[x],"/")
    routey <- cbind(routey,route)
  }
}
routey <- as.vector(routey)



library(raster)
library(tidyverse)
t1 <- list.files("E:/临时/FUT/B2",pattern = "tif",full.names = T)
#### 
library(parallel) #用于并行计算
library(snowfall)  # 载入snowfall包
sfInit(parallel = TRUE, cpus = detectCores() - 4)
sfLibrary(raster) 
sfLibrary(base)
sfLibrary(tidyverse)
sfExport("routey")
sfExport("t1")
export_band <- function(x){
  t1 <- stack(t1[x]) %>% as.list(.)
  export <- function(y){
    output <- paste0(routey[x],names(t1[[y]]),".tif")
    writeRaster(t1[[y]],output,format ='GTiff',overwrite=TRUE )
  }
  sfLapply(1:19,export)
}
lapply(1:16,export_band)



### 构建未来气候变量下的变量求均值：
# 总体思路导出每个栅格的图层值；
setwd("E:/临时/FUT")

## routem ####
setwddd <- "E:/临时/FUT/MIR"
times <- c("202040","204060","206080","2080100")
ssps <- c("ssp126","ssp245","ssp370","ssp585")
routem =c()
### 构建文件路径：routey ####
for(i in 1:4){
  for(x in 1:4){
    route <- paste0(setwddd,"/",ssps[i],"-",times[x],"/")
    routem <- cbind(routem ,route)
  }
}

## routec  ####
setwddd <- "E:/临时/FUT/CNRM"
times <- c("202040","204060","206080","2080100")
ssps <- c("ssp126","ssp245","ssp370","ssp585")
routec =c()
### 构建文件路径：routey ####
for(i in 1:4){
  for(x in 1:4){
    route <- paste0(setwddd,"/",ssps[i],"-",times[x],"/")
    routec <- cbind(routec ,route)
  }
}

## routeb ####
setwddd <- "E:/临时/FUT/BBCMR"
times <- c("202040","204060","206080","2080100")
ssps <- c("ssp126","ssp245","ssp370","ssp585")
routeb  =c()
### 构建文件路径：routey ####
for(i in 1:4){
  for(x in 1:4){
    route <- paste0(setwddd,"/",ssps[i],"-",times[x],"/")
    routeb <- cbind(routeb  ,route)
  }
}


routeb <- as.vector(routeb)
for(i in 1:16){
  dir.create(routeb[i])
}
routey[1]




## routee ####
dir.create("E:/临时/FUT/averagefut")
setwddd <- "E:/临时/FUT/averagefut"
times <- c("202040","204060","206080","2080100")
ssps <- c("ssp126","ssp245","ssp370","ssp585")
routee  =c()
### 构建文件路径：routey ####
for(i in 1:4){
  for(x in 1:4){
    route <- paste0(setwddd,"/",ssps[i],"-",times[x],"/")
    routee <- cbind(routee  ,route)
  }
}
routee <- as.vector(routee)
lapply(routee,function(x){dir.create(x)})

## 得到路线对应的参数值：
## 输入路径：
routem <- as.vector(routem)
routeb <- as.vector(routeb)
routec  <- as.vector(routec)
## 输出路径：
routee

library(raster)
library(tidyverse)
library(dismo)
## 构建输出路径的名字：
nam <- c()
rr1 <- list.files(routem[1],pattern = "tif",full.names = T)
for(i in 1:19){
  t <- strsplit(rr1,"0.")
  nam <- c(t[[i]][7],nam)
}
nam <- rev(nam)
nam[2]="10.tif"
nam <- paste0("BIO",nam)
nm2 <-list()
for(a in 1:16){
   nm2 <- cbind(nm2, paste0(routee[a],nam))
}

## nm2为所有导出文件的文件名：

### 批量运行计算，求平均值，并导出结果：####
library(parallel) #用于并行计算
library(snowfall)  # 载入snowfall包
sfInit(parallel = TRUE, cpus = detectCores() - 6)
sfLibrary(raster) 
sfLibrary(base)
sfLibrary(tidyverse)
sfExport("routem")
sfExport("routeb")
sfExport("routec")

sfExport("nm2")

meanx <- function(x){
  rr1 <- list.files(routem[x],pattern = "tif",full.names = T)
  rr2 <- list.files(routeb[x],pattern = "tif",full.names = T)
  rr3 <- list.files(routec[x],pattern = "tif",full.names = T)
  meany <- function(y){
    s1 <- raster(rr1[y])
    s2 <- raster(rr2[y])
    s3 <- raster(rr3[y])
    s4 <- (s1+s2+s3)/3
    output <- nm2[,x][y] %>% unlist(.)
    writeRaster(s4,output,format ='GTiff',overwrite=TRUE ) 
  }
  sfLapply(1:19,meany)
}
lapply(1:16,meanx)

```



### 4.5  现代环境数据批量掩膜及转换为asc文件

```{r eval =F}
##以中国范围为例，从全球环境信息图层中提取环境信息：
## 养成习惯：
rm(list = ls())
## 设置工作路径：
setwd("E:\\环境数据")
list.files()
## 下载当代环境数据从worldclim中；
library(raster)
## 两种方式加载数据：
##方法１：使用raster::getData() ----
currentEnv1 <- getData("worldclim", var="bio", res=10)
###方法2：解压网页下载数据构建stack()-----
## 下载网页数据并解压缩：
## 使用download.file()下载网页文件：
##  使用unzip解压缩到指定文件夹；
link <- "https://biogeo.ucdavis.edu/data/worldclim/v2.1/base/wc2.1_10m_bio.zip"
download.file(link,destfile = "./") ##没有权限,无法下载;
dir.create("./wc2.5_bio")
unzip("./wc2.1_2.5m_bio.zip",exdir = "./wc2.5_bio")

##构建stack()
tif2 <- list.files (path=paste0("./wc2.5_bio"),pattern='tif', full.names=TRUE )
currentEnv2 <- stack(tif2)

## 加载中国范围shp

## 方法1：利用getData()
## 利用此网站查询国家代码：https://gadm.org ##此国家数据集中国部分有问题；
## 查询代码的方式无法直接查询，可以下载最低等级数据查看
chinashp <- raster::getData('GADM',country='CHN', level=0)
##　plot(chinashp)

## 方法2:加载本地shp文件：----
## 查看文件对应位置:
list.files("./国家基础地理信息系统SHP文件/国界",full.names = T)
## 注意这里的chinashp和chinashp2的投影坐标系是不一致的；
library(rgdal)
chinashp2<-readOGR('./国家基础地理信息系统SHP文件/国界/bou1_4p.shp')
plot(rgdaltest)

## 基于shp文件进行tif文件批量掩膜:----
## 使用raster::crop
library(raster)
currenCHN <- mask(crop(currentEnv2,chinashp),chinashp)
##基于构建的掩膜stack()批量将文件导出到指定文件夹:
d_list = as.list(currenCHN)  ##解开栅格组，构成列表的形式；
## 创建对应文件夹:
dir.create('./CHN_WC2.5_BIO') 
## 可以导入到同一文件夹,也可以导入到不同文件夹;
## dir.create('./CHN_WC2.5_BIO_tif') 
## dir.create('./CHN_WC2.5_BIO_asc') 
##需要注意下面的路径必须使用全拼路径：
export_masktif_asc <- function(x){
  names = names(x)
  output1 = paste0('E:/环境数据/CHN_WC2.5_BIO/',names,'.tif')
  output2 = paste0('E:/环境数据/CHN_WC2.5_BIO/',names,'.asc')
  writeRaster(x,output1,format ='GTiff' ,
              overwrite = T)
  writeRaster(x,output2,format ='ascii' ,
           overwrite = T)}
lapply(d_list,export_masktif_asc)
```

### 4.6 世界土壤数据HSWD批处理

```{r eval =F}
##NC数据单波段分解：##且仅支持nc格式，不支持nc4格式；
library(raster)
# read the netcdf file as raster
nc_raster = raster("input_file.nc")
# if raster crs is NA, set the correct projection using proj4
projection(nc_raster) = CRS("+proj=longlat +ellps=WGS84 +datum=WGS84")  
# save output
writeRaster(nc_raster, "nc_raster.tif", "GTiff")
```

```{r eval =F}
## 一代土壤数据库：

```

```{r eval =F}
####NC数据多波段分解：##支持nc4格式，并可以通过多属性批量导出，参考#TIF单波段分解多波段；## 二代土壤数据库：
##可参考 https://www.jianshu.com/p/50fac745eb76
##参考  https://www.jianshu.com/p/1f327f0c48e9
##此数据形式对应于HWSD数据集；
library(raster)
library(ncdf4)
setwd('E:/环境数据/HWSD_1247/data')
###查看nc数据的组成
nc1 <- nc_open("S_C.nc4") 
names(nc1$var)
##导出数据
input_nc = 'E:/环境数据/HWSD_1247/data/S_C.nc4'
varname = 's_c'
nc_raster = raster(input_nc, varname = varname)
projection(nc_raster) = CRS("+proj=longlat +ellps=WGS84 +datum=WGS84")  
# save output
writeRaster(nc_raster, "E:/环境数据/HWSD_1247/nc_raster.tif", "GTiff", overwrite = TRUE)

##同步导出多个nc数据为tif格式：
library(raster)
library(ncdf4)
setwd('E:/环境数据/HWSD_1247/data')
##创建输出目录：
dir.create("E:/环境数据/HWSD_1247/output")
###提取所有nc格式的数据名
filenames <- list.files("./")
## 输入数据路径
filepaths <- lapply(filenames, function(x)paste(".",'/',x,sep = ""))   
##输出数据路径：
names <-strsplit(filenames,split=".",fixed=TRUE)
name <- unlist(lapply(names,head,1))
out_filename<-lapply(name, function(x)paste(x,".tif",sep = ""))      #输出tif格式
out_path<-lapply(out_filename, function(x){paste("E:/环境数据/HWSD_1247/output",x,sep = "/")}) 
##下一步实验，将filepaths中数据作为raster的参数输入：
for(i in 1:28){
  writeRaster(raster(filepaths[[i]]),out_path[[i]], format = 'GTiff', overwrite = TRUE)
}
                     
                  
```

### 4.8 HDF转tif

```
library(gdalUtils)

# Provides detailed data on hdf4 files but takes ages

gdalinfo("MOD17A3H.A2000001.h21v09.006.2015141183401.hdf")

# Tells me what subdatasets are within my hdf4 MODIS files and makes them into a list

sds <- get_subdatasets("MOD17A3H.A2000001.h21v09.006.2015141183401.hdf")
sds

[1] "HDF4_EOS:EOS_GRID:MOD17A3H.A2000001.h21v09.006.2015141183401.hdf:MOD_Grid_MOD17A3H:Npp_500m"   
[2] "HDF4_EOS:EOS_GRID:MOD17A3H.A2000001.h21v09.006.2015141183401.hdf:MOD_Grid_MOD17A3H:Npp_QC_500m"

# I'm only interested in the first subdataset and I can use gdal_translate to convert it to a .tif

gdal_translate(sds[1], dst_dataset = "NPP2000.tif")

# Load and plot the new .tif

rast <- raster("NPP2000.tif")
plot(rast)

# If you have lots of files then you can make a loop to do all this for you

files <- dir(pattern = ".hdf")
files

 [1] "MOD17A3H.A2000001.h21v09.006.2015141183401.hdf" "MOD17A3H.A2001001.h21v09.006.2015148124025.hdf"
 [3] "MOD17A3H.A2002001.h21v09.006.2015153182349.hdf" "MOD17A3H.A2003001.h21v09.006.2015166203852.hdf"
 [5] "MOD17A3H.A2004001.h21v09.006.2015099031743.hdf" "MOD17A3H.A2005001.h21v09.006.2015113012334.hdf"
 [7] "MOD17A3H.A2006001.h21v09.006.2015125163852.hdf" "MOD17A3H.A2007001.h21v09.006.2015169164508.hdf"
 [9] "MOD17A3H.A2008001.h21v09.006.2015186104744.hdf" "MOD17A3H.A2009001.h21v09.006.2015198113503.hdf"
[11] "MOD17A3H.A2010001.h21v09.006.2015216071137.hdf" "MOD17A3H.A2011001.h21v09.006.2015230092603.hdf"
[13] "MOD17A3H.A2012001.h21v09.006.2015254070417.hdf" "MOD17A3H.A2013001.h21v09.006.2015272075433.hdf"
[15] "MOD17A3H.A2014001.h21v09.006.2015295062210.hdf"

filename <- substr(files,11,14)
filename <- paste0("NPP", filename, ".tif")
filename

[1] "NPP2000.tif" "NPP2001.tif" "NPP2002.tif" "NPP2003.tif" "NPP2004.tif" "NPP2005.tif" "NPP2006.tif" "NPP2007.tif" "NPP2008.tif"
[10] "NPP2009.tif" "NPP2010.tif" "NPP2011.tif" "NPP2012.tif" "NPP2013.tif" "NPP2014.tif"

i <- 1

for (i in 1:15){
  sds <- get_subdatasets(files[i])
  gdal_translate(sds[1], dst_dataset = filename[i])
}
```

### 4.9批量下载soilgrid数据：

```r
## 网站：url = "https://files.isric.org/soilgrids/latest/data/" # Path to the webDAV data.

library(tidyverse)
a <- read.csv("a.csv") %>% as.list(.) 
a$url[1]
length(a$url)


library(parallel) #用于并行计算
library(snowfall)  # 载入snowfall包
# 并行初始化

sfInit(parallel = TRUE, cpus = detectCores() - 2)
sfLibrary(raster) 
sfLibrary(base)
sfExport("a")



do <- function(x){
  names <- paste0(1:length(a$url))
  download.file(a$url[x],paste0("E:/sjdata/sand/", names[x],".tif"), mode = 'wb')
}

sfLapply(1:5000,do)


## 
## 注意下载自：global soilgrids 的数据原始数据投影形式为：
igh='+proj=igh +lat_0=0 +lon_0=0 +datum=WGS84 +units=m +no_defs'
# 也即 use the Homolosine projection，即等面积投影的形式；
# 利用arcgis进行批量转换的时候需要注意先进行定义投影在进行投影转转；

s1 <- raster("./ss/1.tif")
igh='+proj=igh +lat_0=0 +lon_0=0 +datum=WGS84 +units=m +no_defs'
crs(s1) <- igh

crs_wgs84 = CRS('+init=EPSG:4326')
(boyaca_nitro_wgs84 = projectRaster(s1, crs=crs_wgs84))

writeRaster(boyaca_nitro_wgs84,"./TTT.TIF")

op <- par(mar = rep(0, 4))  
plot(boyaca_nitro_wgs84)

library(ncdf4)
ncfile = ncdf4::nc_open("C:/Users/admin/Desktop/UiO_PEX_5.0_20181127_2000_2016_5km.nc")
names(ncfile$var)
##########################
input_nc = "C:/Users/admin/Desktop/UiO_PEX_5.0_20181127_2000_2016_5km.nc"
varname = 'PerProb'
nc2raster = stack(input_nc, varname = varname)


## 极地坐标系转wgs84坐标系：
crs1 <- CRS('+init=EPSG:3995')
crs(nc2raster) <- crs1
crs2 <-  CRS('+init=EPSG:4326')
##  冻土翻译为：Permafrost Zonation 
pz <-  projectRaster(nc2raster, crs=crs2)

plot(pz)
writeRaster(pz,"C:/Users/admin/Desktop/Permafrost_Zonation.tif ")
```

### 4.10  构建欧式距离栅格

```
## 利用arcgis构建欧式距离栅格；
# 可用于灯光距离、人口距离和到河流距离等
构建原理：构建线shp，然后定义投影将wgs84，转为墨卡托投影，然后在toolbox中利用欧式距离函数(空间分析空间-距离-欧式距离)，，设置栅格大小为1000m，最大栅格距离为1000000(约为10度)。为了和大部分数据匹配使用，需要将构建好的距离函数栅格，再转为wgs84格式；
# 但要注意这样构建的欧式距离栅格比较适合小尺度建模，在大尺度的分析上，会遇到海洋边界问题；存在的另外一个问题是湖泊的shp数据会和沙漠等空缺较大的数据进行重合，导致数据结果无法理解。
```

### 4.11 大型环境矩阵高效处理的方法：

```r
tf <- tempfile(fileext = '.tif')
tf2 <- tempfile(fileext = '.tif')
writeRaster(r, tf)

newproj <- "+init=epsg:4714"
system(command = paste(paste0("gdalwarp -t_srs \'", newproj, "\' -r bilinear -overwrite"), 
                       tf,
                       tf2))
pr2 <- raster(tf2)

```

### 4.12 生成坡向和坡度数据并可视化

```r
## 制作立体效果的2D地形图：
slope <- terrain(elevation, opt = "slope")
aspect <- terrain(elevation, opt = "aspect")
hill <- hillShade(slope, aspect, 40, 270)
plot(hill, col = grey(0:100/100), legend = FALSE, main = "Spain")
plot(elevation, col = rainbow(25, alpha = 0.35), add = TRUE)
```

### 4.1.3 NC转tif

```r
setwd("C:/Users/admin/Desktop/yy")
input = list.files(pattern = '.tif$')
d = stack(input) ##这里应该是brick转stack；
d_list = as.list(d)
library(parallel) #用于并行计算
library(snowfall)  # 载入snowfall包
sfInit(parallel = TRUE, cpus = detectCores() - 1)
sfLibrary(raster) 
sfLibrary(base)
sfExport("d_list")

dir.create("../ab")
export_band<-function(x){
  names = names(x)
  output = paste0('C:/Users/admin/Desktop/ab/',names,'.tif')
  writeRaster(x,output,format ='GTiff' ,
              overwrite = T)}
sfLapply(d_list,export_band)
sfStop()

## 举例：
setwd("C:\\Users\\admin\\Desktop\\")

library(raster)
library(ncdf4)

ncfile = ncdf4::nc_open("./frs/cru_ts4.04.1971.1980.frs.dat.nc")
names(ncfile$var)

input_nc = "C:/Users/admin/Desktop/frs/cru_ts4.04.1971.1980.frs.dat.nc"
varname = 'frs'
nc2raster = stack(input_nc, varname = varname)


d_list = as.list(nc2raster )
library(parallel) #用于并行计算
library(snowfall)  # 载入snowfall包
sfInit(parallel = TRUE, cpus = detectCores() - 1)
sfLibrary(raster) 
sfLibrary(base)
sfExport("d_list")

dir.create("./frs/frs_1971.1980")
export_band<-function(x){
  names = names(x)
  output = paste0('C:/Users/admin/Desktop//frs/frs_1971.1980/',names,'.tif')
  writeRaster(x,output,format ='GTiff' ,
              overwrite = T)}
sfLapply(d_list,export_band)
sfStop()


ncfile = ncdf4::nc_open("./frs/cru_ts4.04.1981.1990.frs.dat.nc")
names(ncfile$var)

input_nc = "C:/Users/admin/Desktop/frs/cru_ts4.04.1981.1990.frs.dat.nc"
varname = 'frs'
nc2raster = stack(input_nc, varname = varname)
```

